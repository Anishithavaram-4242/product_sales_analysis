{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ðŸš€ E-Commerce Analytics Platform: Advanced Customer Insights & Sales Forecasting\n",
        "\n",
        "**Developed by:** [Anishitha Varma](https://github.com/Anishithavaram-4242)  \n",
        "**GitHub:** [@Anishithavaram-4242](https://github.com/Anishithavaram-4242?tab=repositories)\n",
        "\n",
        "---\n",
        "\n",
        "## Project Overview\n",
        "This notebook performs comprehensive analysis of e-commerce electronics sales data, including:\n",
        "- **Data Preprocessing & Feature Engineering**: Automated cleaning and transformation pipelines\n",
        "- **Customer Segmentation**: K-Means clustering to identify distinct customer groups\n",
        "- **Sales Forecasting**: Time series analysis and Random Forest predictive modeling\n",
        "- **Product Recommendation System**: Collaborative filtering using cosine similarity\n",
        "- **Statistical Analysis**: Correlation analysis, hypothesis testing, and business insights\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "from scipy import stats\n",
        "from scipy.stats import chi2_contingency\n",
        "\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "sns.set_palette(\"husl\")\n",
        "plt.rcParams['figure.figsize'] = (12, 6)\n",
        "\n",
        "print(\"Libraries imported successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Data Loading and Initial Exploration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_csv('electronics.csv')\n",
        "\n",
        "print(f\"Dataset shape: {df.shape}\")\n",
        "print(f\"\\nColumn names: {df.columns.tolist()}\")\n",
        "print(f\"\\nData types:\\n{df.dtypes}\")\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\" * 60)\n",
        "print(\"DATASET INFORMATION\")\n",
        "print(\"=\" * 60)\n",
        "df.info()\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"MISSING VALUES\")\n",
        "print(\"=\" * 60)\n",
        "print(df.isnull().sum())\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"DUPLICATE ROWS\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Total duplicates: {df.duplicated().sum()}\")\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"BASIC STATISTICS\")\n",
        "print(\"=\" * 60)\n",
        "df.describe()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Data Preprocessing and Feature Engineering\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data = df.copy()\n",
        "\n",
        "data['timestamp'] = pd.to_datetime(data['timestamp'])\n",
        "\n",
        "data['year'] = data['timestamp'].dt.year\n",
        "data['month'] = data['timestamp'].dt.month\n",
        "data['day_of_week'] = data['timestamp'].dt.dayofweek\n",
        "data['quarter'] = data['timestamp'].dt.quarter\n",
        "data['is_weekend'] = (data['day_of_week'] >= 5).astype(int)\n",
        "\n",
        "data['user_id'] = data['user_id'].astype(str)\n",
        "data['item_id'] = data['item_id'].astype(str)\n",
        "\n",
        "data['rating'] = data['rating'].astype(float)\n",
        "\n",
        "print(\"Feature engineering completed!\")\n",
        "print(f\"\\nNew columns: {[col for col in data.columns if col not in df.columns]}\")\n",
        "data.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "initial_shape = data.shape[0]\n",
        "data = data.drop_duplicates()\n",
        "final_shape = data.shape[0]\n",
        "print(f\"Removed {initial_shape - final_shape} duplicate rows\")\n",
        "print(f\"Final dataset shape: {data.shape}\")\n",
        "\n",
        "print(\"\\nMissing values after preprocessing:\")\n",
        "print(data.isnull().sum())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Exploratory Data Analysis (EDA)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "sns.countplot(data=data, x='rating', ax=axes[0], palette='viridis')\n",
        "axes[0].set_title('Distribution of Ratings', fontsize=14, fontweight='bold')\n",
        "axes[0].set_xlabel('Rating')\n",
        "axes[0].set_ylabel('Count')\n",
        "\n",
        "sns.boxplot(data=data, y='rating', ax=axes[1], palette='viridis')\n",
        "axes[1].set_title('Rating Distribution (Box Plot)', fontsize=14, fontweight='bold')\n",
        "axes[1].set_ylabel('Rating')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\nRating Statistics:\")\n",
        "print(data['rating'].describe())\n",
        "print(f\"\\nMode rating: {data['rating'].mode()[0]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "\n",
        "yearly_sales = data.groupby('year').size()\n",
        "axes[0, 0].bar(yearly_sales.index, yearly_sales.values, color='steelblue', alpha=0.7)\n",
        "axes[0, 0].set_title('Total Sales by Year', fontsize=14, fontweight='bold')\n",
        "axes[0, 0].set_xlabel('Year')\n",
        "axes[0, 0].set_ylabel('Number of Transactions')\n",
        "axes[0, 0].grid(axis='y', alpha=0.3)\n",
        "\n",
        "monthly_sales = data.groupby('month').size()\n",
        "month_names = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', \n",
        "               'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
        "axes[0, 1].plot(monthly_sales.index, monthly_sales.values, marker='o', linewidth=2, markersize=8)\n",
        "axes[0, 1].set_title('Sales Trend by Month', fontsize=14, fontweight='bold')\n",
        "axes[0, 1].set_xlabel('Month')\n",
        "axes[0, 1].set_ylabel('Number of Transactions')\n",
        "axes[0, 1].set_xticks(range(1, 13))\n",
        "axes[0, 1].set_xticklabels(month_names, rotation=45)\n",
        "axes[0, 1].grid(alpha=0.3)\n",
        "\n",
        "quarterly_sales = data.groupby('quarter').size()\n",
        "axes[1, 0].bar(quarterly_sales.index, quarterly_sales.values, color='coral', alpha=0.7)\n",
        "axes[1, 0].set_title('Sales by Quarter', fontsize=14, fontweight='bold')\n",
        "axes[1, 0].set_xlabel('Quarter')\n",
        "axes[1, 0].set_ylabel('Number of Transactions')\n",
        "axes[1, 0].grid(axis='y', alpha=0.3)\n",
        "\n",
        "weekend_analysis = data.groupby('is_weekend').size()\n",
        "axes[1, 1].pie(weekend_analysis.values, labels=['Weekday', 'Weekend'], autopct='%1.1f%%',\n",
        "               startangle=90, colors=['lightblue', 'lightcoral'])\n",
        "axes[1, 1].set_title('Weekend vs Weekday Sales', fontsize=14, fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "top_categories = data['category'].value_counts().head(10)\n",
        "\n",
        "plt.figure(figsize=(14, 8))\n",
        "colors = sns.color_palette(\"husl\", len(top_categories))\n",
        "bars = plt.barh(range(len(top_categories)), top_categories.values, color=colors)\n",
        "plt.yticks(range(len(top_categories)), top_categories.index)\n",
        "plt.xlabel('Number of Transactions', fontsize=12)\n",
        "plt.title('Top 10 Product Categories by Sales Volume', fontsize=16, fontweight='bold')\n",
        "plt.gca().invert_yaxis()\n",
        "\n",
        "for i, (idx, val) in enumerate(zip(top_categories.index, top_categories.values)):\n",
        "    plt.text(val + 1000, i, f'{val:,}', va='center', fontsize=10)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\nTotal unique categories: {data['category'].nunique()}\")\n",
        "print(f\"\\nCategory with most sales: {top_categories.index[0]} ({top_categories.values[0]:,} transactions)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Customer Behavior Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "customer_features = data.groupby('user_id').agg({\n",
        "    'rating': ['mean', 'count', 'std'],\n",
        "    'item_id': 'nunique',\n",
        "    'category': 'nunique'\n",
        "}).reset_index()\n",
        "\n",
        "customer_features.columns = ['user_id', 'avg_rating', 'total_reviews', 'rating_std', \n",
        "                            'unique_products', 'unique_categories']\n",
        "customer_features = customer_features.fillna(0)\n",
        "\n",
        "customer_features['engagement_score'] = (\n",
        "    customer_features['total_reviews'] * 0.4 +\n",
        "    customer_features['unique_products'] * 0.3 +\n",
        "    customer_features['unique_categories'] * 0.3\n",
        ")\n",
        "\n",
        "print(\"Customer features created:\")\n",
        "print(customer_features.head())\n",
        "print(f\"\\nTotal unique customers: {len(customer_features)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "\n",
        "axes[0, 0].hist(customer_features['avg_rating'], bins=30, color='skyblue', edgecolor='black', alpha=0.7)\n",
        "axes[0, 0].set_title('Distribution of Average Ratings per Customer', fontsize=14, fontweight='bold')\n",
        "axes[0, 0].set_xlabel('Average Rating')\n",
        "axes[0, 0].set_ylabel('Number of Customers')\n",
        "axes[0, 0].axvline(customer_features['avg_rating'].mean(), color='red', \n",
        "                   linestyle='--', label=f'Mean: {customer_features[\"avg_rating\"].mean():.2f}')\n",
        "axes[0, 0].legend()\n",
        "axes[0, 0].grid(alpha=0.3)\n",
        "\n",
        "axes[0, 1].hist(customer_features['total_reviews'], bins=50, color='lightgreen', edgecolor='black', alpha=0.7)\n",
        "axes[0, 1].set_title('Distribution of Reviews per Customer', fontsize=14, fontweight='bold')\n",
        "axes[0, 1].set_xlabel('Number of Reviews')\n",
        "axes[0, 1].set_ylabel('Number of Customers')\n",
        "axes[0, 1].set_xlim(0, 100)\n",
        "axes[0, 1].grid(alpha=0.3)\n",
        "\n",
        "axes[1, 0].hist(customer_features['engagement_score'], bins=50, color='coral', edgecolor='black', alpha=0.7)\n",
        "axes[1, 0].set_title('Customer Engagement Score Distribution', fontsize=14, fontweight='bold')\n",
        "axes[1, 0].set_xlabel('Engagement Score')\n",
        "axes[1, 0].set_ylabel('Number of Customers')\n",
        "axes[1, 0].grid(alpha=0.3)\n",
        "\n",
        "scatter = axes[1, 1].scatter(customer_features['total_reviews'], \n",
        "                             customer_features['avg_rating'],\n",
        "                             c=customer_features['engagement_score'],\n",
        "                             cmap='viridis', alpha=0.6, s=20)\n",
        "axes[1, 1].set_title('Customer Rating vs Review Count', fontsize=14, fontweight='bold')\n",
        "axes[1, 1].set_xlabel('Total Reviews')\n",
        "axes[1, 1].set_ylabel('Average Rating')\n",
        "axes[1, 1].set_xlim(0, 100)\n",
        "plt.colorbar(scatter, ax=axes[1, 1], label='Engagement Score')\n",
        "axes[1, 1].grid(alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Customer Segmentation using K-Means Clustering\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "features_for_clustering = customer_features[['avg_rating', 'total_reviews', \n",
        "                                             'unique_products', 'unique_categories']].copy()\n",
        "\n",
        "features_for_clustering = features_for_clustering.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "features_scaled = scaler.fit_transform(features_for_clustering)\n",
        "\n",
        "inertias = []\n",
        "K_range = range(2, 8)\n",
        "for k in K_range:\n",
        "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
        "    kmeans.fit(features_scaled)\n",
        "    inertias.append(kmeans.inertia_)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(K_range, inertias, 'bo-', linewidth=2, markersize=8)\n",
        "plt.xlabel('Number of Clusters (k)', fontsize=12)\n",
        "plt.ylabel('Inertia', fontsize=12)\n",
        "plt.title('Elbow Method for Optimal k', fontsize=14, fontweight='bold')\n",
        "plt.grid(alpha=0.3)\n",
        "plt.show()\n",
        "\n",
        "print(\"Elbow method completed. Optimal k appears to be around 3-4 clusters.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "n_clusters = 4\n",
        "kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
        "customer_features['cluster'] = kmeans.fit_predict(features_scaled)\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "scatter1 = axes[0].scatter(customer_features['total_reviews'], \n",
        "                          customer_features['avg_rating'],\n",
        "                          c=customer_features['cluster'], \n",
        "                          cmap='Set1', alpha=0.6, s=30)\n",
        "axes[0].set_title('Customer Clusters: Rating vs Review Count', fontsize=14, fontweight='bold')\n",
        "axes[0].set_xlabel('Total Reviews')\n",
        "axes[0].set_ylabel('Average Rating')\n",
        "axes[0].set_xlim(0, 100)\n",
        "axes[0].grid(alpha=0.3)\n",
        "plt.colorbar(scatter1, ax=axes[0], label='Cluster')\n",
        "\n",
        "scatter2 = axes[1].scatter(customer_features['unique_products'], \n",
        "                          customer_features['unique_categories'],\n",
        "                          c=customer_features['cluster'], \n",
        "                          cmap='Set1', alpha=0.6, s=30)\n",
        "axes[1].set_title('Customer Clusters: Product Diversity', fontsize=14, fontweight='bold')\n",
        "axes[1].set_xlabel('Unique Products')\n",
        "axes[1].set_ylabel('Unique Categories')\n",
        "axes[1].grid(alpha=0.3)\n",
        "plt.colorbar(scatter2, ax=axes[1], label='Cluster')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"CLUSTER CHARACTERISTICS\")\n",
        "print(\"=\" * 60)\n",
        "cluster_summary = customer_features.groupby('cluster').agg({\n",
        "    'avg_rating': 'mean',\n",
        "    'total_reviews': 'mean',\n",
        "    'unique_products': 'mean',\n",
        "    'unique_categories': 'mean',\n",
        "    'user_id': 'count'\n",
        "}).round(2)\n",
        "cluster_summary.columns = ['Avg Rating', 'Avg Reviews', 'Avg Unique Products', \n",
        "                          'Avg Unique Categories', 'Customer Count']\n",
        "print(cluster_summary)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Sales Forecasting with Time Series Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "time_series_data = data.groupby([data['timestamp'].dt.to_period('M')]).size().reset_index()\n",
        "time_series_data.columns = ['period', 'sales_count']\n",
        "time_series_data['period'] = time_series_data['period'].astype(str)\n",
        "time_series_data['date'] = pd.to_datetime(time_series_data['period'])\n",
        "time_series_data = time_series_data.sort_values('date').reset_index(drop=True)\n",
        "\n",
        "plt.figure(figsize=(16, 6))\n",
        "plt.plot(time_series_data['date'], time_series_data['sales_count'], \n",
        "         marker='o', linewidth=2, markersize=6, color='steelblue')\n",
        "plt.title('Sales Trend Over Time', fontsize=16, fontweight='bold')\n",
        "plt.xlabel('Date', fontsize=12)\n",
        "plt.ylabel('Number of Sales', fontsize=12)\n",
        "plt.grid(alpha=0.3)\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\nTime series statistics:\")\n",
        "print(time_series_data['sales_count'].describe())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "window_size = 3\n",
        "time_series_data['moving_avg'] = time_series_data['sales_count'].rolling(window=window_size).mean()\n",
        "\n",
        "time_series_data['month_num'] = time_series_data['date'].dt.month\n",
        "time_series_data['year_num'] = time_series_data['date'].dt.year\n",
        "time_series_data['period_num'] = range(len(time_series_data))\n",
        "\n",
        "forecast_data = time_series_data[['period_num', 'month_num', 'year_num', 'sales_count']].dropna()\n",
        "\n",
        "if len(forecast_data) > 5:\n",
        "    X = forecast_data[['period_num', 'month_num']]\n",
        "    y = forecast_data['sales_count']\n",
        "    \n",
        "    split_idx = int(len(forecast_data) * 0.8)\n",
        "    X_train, X_test = X[:split_idx], X[split_idx:]\n",
        "    y_train, y_test = y[:split_idx], y[split_idx:]\n",
        "    \n",
        "    rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "    rf_model.fit(X_train, y_train)\n",
        "    \n",
        "    y_pred = rf_model.predict(X_test)\n",
        "    \n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    \n",
        "    plt.figure(figsize=(16, 6))\n",
        "    plt.plot(time_series_data['date'], time_series_data['sales_count'], \n",
        "             label='Actual Sales', marker='o', linewidth=2, markersize=6)\n",
        "    plt.plot(time_series_data['date'], time_series_data['moving_avg'], \n",
        "             label=f'Moving Average (window={window_size})', linewidth=2, linestyle='--')\n",
        "    \n",
        "    test_dates = time_series_data['date'].iloc[split_idx:split_idx+len(y_test)]\n",
        "    plt.plot(test_dates, y_pred, label='Forecasted Sales', \n",
        "             marker='s', linewidth=2, markersize=6, color='red')\n",
        "    \n",
        "    plt.title('Sales Forecasting: Actual vs Predicted', fontsize=16, fontweight='bold')\n",
        "    plt.xlabel('Date', fontsize=12)\n",
        "    plt.ylabel('Number of Sales', fontsize=12)\n",
        "    plt.legend()\n",
        "    plt.grid(alpha=0.3)\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    print(f\"\\nForecasting Model Performance:\")\n",
        "    print(f\"Mean Squared Error: {mse:.2f}\")\n",
        "    print(f\"RÂ² Score: {r2:.4f}\")\n",
        "else:\n",
        "    print(\"Insufficient data for forecasting model\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Statistical Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "numeric_cols = ['rating', 'year', 'month', 'day_of_week', 'quarter']\n",
        "correlation_matrix = data[numeric_cols].corr()\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, \n",
        "            square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
        "plt.title('Correlation Matrix of Numerical Features', fontsize=14, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "ratings_sample = data['rating'].sample(min(5000, len(data)), random_state=42)\n",
        "shapiro_stat, shapiro_p = stats.shapiro(ratings_sample)\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"STATISTICAL TESTS\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"\\nShapiro-Wilk Normality Test (Rating Distribution):\")\n",
        "print(f\"  Statistic: {shapiro_stat:.4f}\")\n",
        "print(f\"  p-value: {shapiro_p:.4e}\")\n",
        "print(f\"  Result: {'Not normally distributed' if shapiro_p < 0.05 else 'Normally distributed'}\")\n",
        "\n",
        "yearly_stats = data.groupby('year').agg({\n",
        "    'rating': ['mean', 'count']\n",
        "}).reset_index()\n",
        "yearly_stats.columns = ['year', 'avg_rating', 'total_sales']\n",
        "\n",
        "print(f\"\\nYear-over-Year Statistics:\")\n",
        "print(yearly_stats)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Product Recommendation System (Collaborative Filtering)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sample_size = min(50000, len(data))\n",
        "sample_data = data.sample(n=sample_size, random_state=42)\n",
        "\n",
        "user_item_matrix = sample_data.pivot_table(\n",
        "    index='user_id', \n",
        "    columns='item_id', \n",
        "    values='rating', \n",
        "    fill_value=0\n",
        ")\n",
        "\n",
        "print(f\"User-Item Matrix Shape: {user_item_matrix.shape}\")\n",
        "print(f\"Matrix Sparsity: {(user_item_matrix == 0).sum().sum() / (user_item_matrix.shape[0] * user_item_matrix.shape[1]) * 100:.2f}%\")\n",
        "\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "item_similarity = cosine_similarity(user_item_matrix.T)\n",
        "item_similarity_df = pd.DataFrame(\n",
        "    item_similarity, \n",
        "    index=user_item_matrix.columns, \n",
        "    columns=user_item_matrix.columns\n",
        ")\n",
        "\n",
        "print(\"\\nItem similarity matrix created!\")\n",
        "print(f\"Shape: {item_similarity_df.shape}\")\n",
        "\n",
        "def get_recommendations(item_id, n_recommendations=5):\n",
        "    if item_id not in item_similarity_df.index:\n",
        "        return []\n",
        "    \n",
        "    similar_items = item_similarity_df[item_id].sort_values(ascending=False)\n",
        "    similar_items = similar_items[similar_items.index != item_id]\n",
        "    return similar_items.head(n_recommendations).index.tolist()\n",
        "\n",
        "if len(user_item_matrix.columns) > 0:\n",
        "    sample_item = user_item_matrix.columns[0]\n",
        "    recommendations = get_recommendations(sample_item, n_recommendations=5)\n",
        "    print(f\"\\nExample: Recommendations for item {sample_item}:\")\n",
        "    print(f\"Top 5 similar items: {recommendations[:5]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Business Insights and Recommendations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\" * 70)\n",
        "print(\"BUSINESS INSIGHTS & STRATEGIC RECOMMENDATIONS\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "peak_year = data.groupby('year').size().idxmax()\n",
        "peak_month = data.groupby('month').size().idxmax()\n",
        "month_names = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', \n",
        "               'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
        "\n",
        "print(f\"\\n1. SALES PERFORMANCE:\")\n",
        "print(f\"   â€¢ Peak sales year: {peak_year}\")\n",
        "print(f\"   â€¢ Peak sales month: {month_names[peak_month-1]} ({peak_month})\")\n",
        "print(f\"   â€¢ Total transactions: {len(data):,}\")\n",
        "\n",
        "top_3_categories = data['category'].value_counts().head(3)\n",
        "print(f\"\\n2. TOP PERFORMING CATEGORIES:\")\n",
        "for idx, (cat, count) in enumerate(top_3_categories.items(), 1):\n",
        "    percentage = (count / len(data)) * 100\n",
        "    print(f\"   {idx}. {cat}: {count:,} transactions ({percentage:.2f}%)\")\n",
        "\n",
        "print(f\"\\n3. CUSTOMER SEGMENTATION:\")\n",
        "for cluster_id in sorted(customer_features['cluster'].unique()):\n",
        "    cluster_data = customer_features[customer_features['cluster'] == cluster_id]\n",
        "    print(f\"   Cluster {cluster_id}:\")\n",
        "    print(f\"      â€¢ Customers: {len(cluster_data):,}\")\n",
        "    print(f\"      â€¢ Avg Rating: {cluster_data['avg_rating'].mean():.2f}\")\n",
        "    print(f\"      â€¢ Avg Reviews: {cluster_data['total_reviews'].mean():.1f}\")\n",
        "    print(f\"      â€¢ Product Diversity: {cluster_data['unique_products'].mean():.1f}\")\n",
        "\n",
        "avg_rating = data['rating'].mean()\n",
        "high_ratings = (data['rating'] >= 4).sum()\n",
        "high_rating_pct = (high_ratings / len(data)) * 100\n",
        "\n",
        "print(f\"\\n4. CUSTOMER SATISFACTION:\")\n",
        "print(f\"   â€¢ Average rating: {avg_rating:.2f}/5.0\")\n",
        "print(f\"   â€¢ High ratings (â‰¥4): {high_ratings:,} ({high_rating_pct:.2f}%)\")\n",
        "\n",
        "print(f\"\\n5. STRATEGIC RECOMMENDATIONS:\")\n",
        "print(f\"   â€¢ Focus marketing efforts during {month_names[peak_month-1]} for maximum impact\")\n",
        "print(f\"   â€¢ Prioritize inventory for top categories: {', '.join(top_3_categories.index[:2])}\")\n",
        "print(f\"   â€¢ Develop targeted campaigns for different customer segments\")\n",
        "print(f\"   â€¢ Implement recommendation system to increase cross-selling\")\n",
        "print(f\"   â€¢ Monitor sales trends and adjust inventory accordingly\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Summary and Conclusions\n",
        "\n",
        "### Key Findings:\n",
        "1. **Sales Trends**: Identified peak sales periods and seasonal patterns\n",
        "2. **Customer Segmentation**: Successfully segmented customers into 4 distinct groups\n",
        "3. **Product Performance**: Analyzed top-performing categories and products\n",
        "4. **Forecasting**: Built predictive models for sales forecasting\n",
        "5. **Recommendations**: Developed collaborative filtering system for product recommendations\n",
        "\n",
        "### Technical Achievements:\n",
        "- Advanced data preprocessing and feature engineering\n",
        "- Machine learning models (K-Means clustering, Random Forest regression)\n",
        "- Statistical analysis and hypothesis testing\n",
        "- Time series analysis and forecasting\n",
        "- Collaborative filtering recommendation system\n",
        "\n",
        "### Business Value:\n",
        "- Data-driven insights for strategic decision-making\n",
        "- Customer segmentation for targeted marketing\n",
        "- Sales forecasting for inventory planning\n",
        "- Product recommendations to increase revenue\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
